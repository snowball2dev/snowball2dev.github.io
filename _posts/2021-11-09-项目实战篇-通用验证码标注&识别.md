---
layout:     post
title:      "实战篇-常用验证码标注&识别"
subtitle:   " \"常用验证码标注&识别\""
date:       2021-11-09 15:26:00 +0800
author:     "snowball"
header-img: "img/home-bg-o.jpg"
tags:
    - SpringBoot
    - Vue
    - 项目实战
    - 验证码标注&识别
typora-root-url: ..
---

<!--  “验证码标注&识别. ” -->

### 实战篇-常用验证码标注&识别

#### 简介

大家好，我是Snowball。今天给大家分享的实战项目是常用验证码标注&识别，从想法诞生到实现思路，再到编码实战的整体过程。首先介绍一下验证码基本概念，验证码全称为全自动区分计算机和人类的图灵测试（Completely Automated Public Turing test to tell Computers and Humans Apart，简称CAPTCHA），俗称验证码，是一种区分用户是计算机和人的公共全自动程序。验证码的主要目的是强制人机交互来抵御机器自动化攻击，为了确保服务器系统的稳定和用户信息的安全，大部分网站采用了验证码技术。图片验证码是目前最常用的一种，本文也主要讨论这种验证码的识别。

最初，图片验证码识别的想法最初源于12年的大学阶段，当时的学校教务系统每次抢课系统就崩溃，而且还要特定时间段跟其他同学一起抢指定课程，基本抢不到自己想修的课程，那时候就想绕过系统图片验证码通过代码实现自动抢课，鉴于当时自己编码能力和技术能力有限，机器学习、神经网络相关框架效果较差，最后以各种条件限制实现不了告终~~

XDM，等等，故事还没完，时间回到2021年，做为一名勤于搬砖、善于思考学习的程序猿，在经过几年社会的毒打后，想着以现在自己的项目经验、学习能力和编码功底，以及行业内机器学习、神经网络等AI技术的发展，能不能把多年以来的想法给实现，达到图片验证码高正确率识别预测，训练一个高度可用的CNN模型。在做项目之前经过笔者几天的资料查询过程中，确信高可用的验证码识别模型想法是可以做的，于是开启了CNN神经网络等技术前置知识的漫长学习过程。

几个月过后，项目编码实战出炉，效果嘛，自我感觉还行，基本达到高可用，500张训练数据图，CNN模型单个字符97%以上准确率。

这里先贴项目的工程Git地址，有基础的同学可以去直接拉取项目下来把玩源码：

[Java后台-通用验证码标注系统](https://gitee.com/snowball2dev/DataMarkService) 

[Vue管理后台模板-通用验证码标注系统](https://gitee.com/snowball2dev/DataMarkService-Vue)

[Python-图片验证码识别模型案例](https://gitee.com/snowball2dev/VerifyCodeRecognize-Python)

[标注系统线上效果体验地址](http://139.9.191.103:8084/)



好的，XDM，如果到这里还有兴趣往下看的话，那么就请跟随结合笔者的学习、编码实战过程来了解常用的验证码识别方法和过程。



#### 需求分析

说到图片验证码识别功能，这个功能初步想想也简单，网上搜一下关键词，相关文章和开源项目非常多。以下是github搜索结果：

![QQ图片20210825173036](/img/in-post/post-verifycode-recognize/github搜索结果.png)

乍一看，好像真有免费的午餐，随便下载个CNN-python项目，改几行代码，然后开始疯狂标注数据过程，就能跑出来模型。

笔者自己最初也是这么想的，只求简单粗暴，于是弄了几个项目下来跑了之后，发现代码是可以用，但是效果非常拉跨，单个字符识别正确率很低，70%不到，4-6个字符那正确率就更低了，基本上达不到高正确率，可用性非常一般。对于一个有追求的程序猿，不可能这么就完事了，于是，这就有了这个项目的整活。

在使用这些开源项目的过程中，发现下载的项目实现过程大都分为2种思路，第一种无需图片切割，直接数据标注训练模型；第二种为图片验证码进行字符切割，然后为单个字符进行分类训练。项目执行的具体过程就不演示了，有兴趣的读者开源自行捣鼓，下面就是笔者自己对2种思路适用方式的实践思考总结：

1. 第一种无需图片切割

   优点：简单粗暴，通用性强，直接用各种卷积神经网络模型硬怼图片验证码提取特征，适合知道验证码生成的正向代码过程，用代码生成图片验证码数据给模型训练。

   缺点：数据量小时模型拟合效果差，需要大量人工标注数据，不太适合不知道验证码生成规则，少量标注数据。

2. 第二种进行字符切割

   针对验证码生成规则，分析验证码各种背景干扰、噪声点像素、字体形变和累叠、字符位置随机及个数不定、反色等情况，对图片逆向处理，达到局部字符可切割，降低卷积模型层次，降低数据标注量，实现字符分类。

   优点：可针对单一图片验证码做特殊预处理，可实现部分字符切割，针对字符小图进行分类训练，小批量数据标注就可以训练模型达到高拟合效果，达到可用

   缺点：通用性不强，训练模型只适用特定图片验证码，复杂验证码可能无法切割

   

XDM，等等，还有一种思路：

笔者自己学习OpenCV时想到的，通过图片预处理，轮廓检测，然后对A-Z,0-9字符通过SIFT算法进行特征提取，最后跟需要匹配的字符进行FLANN匹配，理想很丰满，然后编写相关代码后发现由于验证码的正向生成过程导致字符特征变化太大，并不适合，于是放弃采用该思路，代码见python项目image_match.py



根据以上思路总结，根本没有免费的午餐，好的数据和特征工程同等重要，要实现好的效果，都是要根据具体问题具体分析，所以笔者分析自己的图片验证码识别案例，更适合第二种，另外一点原因大批量标注数据人工成本过高，个人不太喜欢。以下将附带案例详细介绍第二种识别思路的实现过程。



#### 实现思路

根据需求初步分析，大概可分为四个步骤：

1. **数据采集/预处理**：http批量下载，OpenCV API使用学习，图片预处理

2. **数据标注**：GUI标注功能开发，人工标注数据阶段，模型训练后预测数据可进行数据集补充

3. **CNN神经网络模型训练**：windows环境，cpu/gpu，学习神经网络框架API，微积分、线代、概率论等前置知识，加深对神经网络模型理解，pytroch框架的使用

4. **项目部署**：linux环境下，标注系统VUE前端部署、标注系统Java后端部署、Python模型部署

以下是Xmind脑图导出效果：

![验证码识别](/img/in-post/post-verifycode-recognize/验证码识别.png)

##### 1.数据采集/预处理/字符图切割

数据采集：根据图片验证码链接进行批量下载图片，最开始时下载个20张先进行手动改文件名进行标注，下载这块代码编写不难，这里不贴代码了，见image_download.py文件

预处理：根据需求分析中的字符切割描述，针对笔者的图片验证码案例情况，需要先进行常规验证码图片预处理，预处理通过OpenCV库实现，处理过程为：

```
原始图->灰度图->中值滤波->二值化->轮廓检测绘制（部分情况才可以加）->字符切割填充
```

大概过程功能简单描述如下，详细原理可以参考OpenCV相关文章和视频，见文章末尾引用链接：

**原始图(RGB)转灰度图**：去除颜色信息，减少图片大小，单通道值方便滤波处理。读者可以脑洞一下，不去除颜色信息，能提取到指定字符颜色的轮廓吗？

**灰度图中值滤波**：进行噪音去除，取中间像素平均值

**二值化**：只留下0、255二种值，方便轮廓检测

**轮廓检测**：这一步主要用于提取字符轮廓矩形坐标，不适合字符挨得特别紧的情况

**字符切割填充**：根据生成的字符轮廓图片矩形坐标进行切割再填充对齐到指定宽高



具体执行效果如下：

![图片清理过程](/img/in-post/post-verifycode-recognize/图片预处理过程.png)



下面是预处理过程部分核心代码，详细代码见image_split.py文件

```
def pre_process_image(img, file_name):
    # 去除边缘
    img = img[2:-2, 2:-2]
    # print(img.shape)

    #得到灰度图
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # show("gray", gray)

    #去除噪音
    blur = cv2.medianBlur(gray, 3)
    # show("blur", blur)

    temp = gray.mean().item()
    #二值化
    ret, threshold = cv2.threshold(blur, temp, 255, cv2.THRESH_BINARY)
    # show("threshold", threshold)

    #保存二值化图片
    if IS_SAVE_FILE:
        cv2.imwrite(DST_IMG_DIR + file_name + "_threshold.png", threshold)
    return threshold
```

执行图片预处理程序后具体效果图1-3如下：

轮廓检测绘制结果1：

![图片预处理结果1](/img/in-post/post-verifycode-recognize/图片预处理结果1.png)



根据图片轮廓进行字符切割结果2：

![图片预处理结果2](/img/in-post/post-verifycode-recognize/图片预处理结果2.png)



根据字符切割图片进行文件分类结果3：

![图片预处理结果3](/img/in-post/post-verifycode-recognize/图片预处理结果3.png)

以上就是字符图片切割的全部过程了，核心过程代码如下：

```
def split_image(file_path):
    file_name = get_file_name(file_path)
    img = read_image(file_path)

    #验证码预处理
    threshold = pre_process_image(img, file_name)

    #查找轮廓边界列表
    contours = find_counters(threshold)

    #过滤合适的轮廓矩形列表
    rect_list,result_rect = get_filter_rect(contours, img, file_name)

    #分割矩形图片
    return split_rect_img(file_path, threshold, rect_list, result_rect)
```

详细代码可以阅读源码，这里说一下这个过程中笔者编写预处理代码遇到的几个问题：

1. 部分图片轮廓检测可以检测到多个轮廓，部分图片只有1-2个轮廓，部分可能一个轮廓都没有，这里代码进行了相应的调整处理，比如过滤大的外部轮廓和较小的内部轮廓，根据剩下的轮廓进行坐标排序，根据部分坐标得到所有字符轮廓
2. 得到4个字符轮廓图片后，每个图片大小不一致，需要进行大小补齐，这个宽高参数需要根据数据集进行调整

以上就是数据采集/预处理的实现过程了，这里稍微说下学习OpenCV相关知识过程的情况，笔者是采用文章+视频间断性学习，大概是20-40个小时左右，然后再开始写具体字符图片切割的代码，读者可根据自己的时间安排学习速度，建议工具类的东西是快速学习，现学现用。好的，接下来介绍高效率、可复用的通用图片验证码数据标注功能实现。



##### 2.高效率数据标注

根据第一大步的实现思路描述，大家应该可以了解到，在最初图片验证码数据的标注过程中，都是手动改文件名进行标注的，这种方式对小数据量标注是比较有效的，但是要标注个几百个图片，那效率是非常低，而且容易出错。于是，笔者思考怎么能提升通用图片验证码数据标注的效率，且能把文件管理起来，随时查询、修改、下载。

最开始，是想着用python的gui框架写个简单工具满足，在尝试了**Tkinter**、**PyQT**框架API使用之后，发现其列表组件操作非常麻烦，而且自定义item项也很复杂，于是就放弃了这种方案。最终采用现在主流的Web页面+后端的应用方案，这块后端技术栈笔者是比较熟练的，前端技术就很一般，基本现学现用，只需要找一个上手快的前端后台管理模板项目改改就行。这里感谢下之前工作的前端同事妹子，给我推荐了直接上手的开源工程，同时也帮助我解决了修改过程的大部分问题。以下是Vue后台管理系统模板开源项目地址：

[Vue-Admin-Template](https://github.com/PanJiaChen/vue-admin-template)

在确定好应用方案后，就需要考虑需要实现的通用图片验证码的需求和功能模块，这里由于文章篇幅所致，就不把所有的具体功能细节分析、设计、实现过程写出来了，这里贴一下主要的功能。以下是通用图片验证码数据标注的相关功能模块：

```
1.用户模块：登录/注册、角色、权限控制等
2.文件模块：用户附件表增删改查、分用户目录存储落盘
3.验证码图片模块：标注验证码拉取生成、标注数据提交/修改、分页查询、批量下载
4.验证码图片模型预测：支持多模型切换预测（时间关系，只做了单模型）
```

数据标注前后端系统的相关代码这里就不写了，有相关基础的可以拉取文章开头的项目链接阅读相关模块代码，下面只给出项目中前后端系统功能实现的主要相关技术中间件、开源框架

**前端技术框架**：

```
vue、vuex、vue-router、axios、element-ui等
```

**后端技术框架**：

```
Spring Boot、Spring Security、Spring MVC、Spring Data Jpa、Redis、Mysql等
```

这里稍微提一下，后端这块采用传统的单机Web/Session技术架构，个人项目勉强够用，企业应用可改成分布式/微服务架构。

以上就是通用图片验证码数据标注系统前后端的功能大概实现内容，有问题的读者可留言或联系小编交流讨论。在笔者经过1-2周空闲时间的数据库设计、前后端项目搭建、功能编码/测试工作后，功能初步实现，接下来来看看项目在windows上的运行效果吧：

**前端运行效果**：

使用IDE： Visual Studio Code

测试环境终端运行：npm run dev

![image-20210826100354837](/img/in-post/post-verifycode-recognize/前端运行效果.png)

**后端运行效果**：

使用IDE： IntelliJ Idea 2019

运行：点击工具栏运行按钮

![image-20210826100516138](/img/in-post/post-verifycode-recognize/后端运行效果.png)



下面是前端系统的部分操作效果演示效果：

**拉取图片验证码生成：**

![image-20210826100731049](/img/in-post/post-verifycode-recognize/拉取图片验证码生成.png)

**标注图片验证码-提交：**

![image-20210826100839768](/img/in-post/post-verifycode-recognize/标注图片验证码-提交.png)

**已标注图片-分页查询/下载/编辑：**

![image-20210826100935923](/img/in-post/post-verifycode-recognize/已标注图片_分页查询下载编辑.png)

**模型预测产生数据（40个字符错了2个~~）：**

![image-20210826101351849](/img/in-post/post-verifycode-recognize/模型预测产生数据.png)

以上就是核心功能的演示效果了，这里注意的点是，CNN模型预测识别功能是需要部署python的神经网络模型项目，这块功能部署的相关内容在下一个步骤会详细描述，这里就只是演示一下效果。

小结一下，经过上面二块功能实现后，我们可以知道图片验证码标注管理可以高效率了，字符图片分割可以批量进行了，那么基础数据都有了，接下来就进入到本篇文章最核心的功能分析和实现内容：字符特征提取-CNN神经网络模型训练。



##### 3.CNN神经网络模型训练/测试/部署

按照学习的好习惯，先搜索网上资源，再脑洞一下，先思考啥是神经网络，啥是卷积，CNN神经网络为啥能提取图片特征，这些问题笔者刚开始全部都遇到过，一脸蒙蔽有没有。不要急，有问题有时候是好事，说明你知道自己那些不知道，等到自己了解和懂得多了，有些问题就迎刃而解。

笔者刚开始在上面的OpenCV知识学习过程中，就尝试用过传统的SIFT算法进行提取图片特征可以进行图片相似度匹配，但是效果都比较差，这里面用的是多维向量特征描述。而神经网络在机器学习的领域为啥这么牛皮，这里面是有数学方面的理论支撑，也有现在计算力和数据量的支持，而卷积神经网络专门用来处理图片特征提取。

刚开始，笔者对这方面的理论知识了解甚少，于是充分利用搜索工具和网上资源，这里分享一下自己学习过程中的文章链接和视频链接，可以保证读者看完基本可以加深对神经网络训练的实战了解，可上手进行项目功能调整。好的，让我们开始学习（卷）起来，以下就是所有内容的链接，没有基础的朋友可以补一补，有基础的可以直接跳过：



**数学基础**

[微积分](https://www.bilibili.com/video/BV1Eb411u7Fw)

[线性代数](https://www.bilibili.com/video/BV1aW411Q7x1)

[概率论](https://www.bilibili.com/video/BV1ot411y7mU)

[计算机数学基础](https://www.bilibili.com/video/BV1AB4y1K7kM)



**OpenCV**

[OpenCV文章专栏](https://blog.csdn.net/yukinoai/category_9283880.html)

[OpenCV-Python视频](https://www.bilibili.com/video/BV1tb4y1C7j7)



**神经网络**

[理解卷积意义](https://www.bilibili.com/video/BV1VV411478E)

[前馈神经网络](https://www.bilibili.com/video/BV1Tt411s7fK)

[神经网络学习理解](https://space.bilibili.com/504715181?spm_id_from=333.788.b_765f7570696e666f.1)



**Python框架使用**

[Numpy中文教程](https://www.runoob.com/numpy/numpy-tutorial.html)

[PyTorch中文教程](https://pytorch.panchuang.net/SecondSection/neural_networks/)

[PyTorch视频](https://www.bilibili.com/video/BV1t64y1t7V8)



以上就是笔者这次项目开发几个月来搜索的优质学习文章和视频资源了，有基础的朋友可以选择性相关知识学习，没有基础而时间充裕的可以恶补基础再动手实战，所谓磨刀不误砍柴工。想快速动手的小伙伴可以快速学习，把对应项目需要的知识点看明白即可。笔者建议的学习方式是确定自己的任务主线，然后边学边练边思考，在项目实战中学习总结是成长最快的方式。

好的，在上面前置知识学习了解的差不多后，相信大家都已经知道CNN神经网络的理论知识了，接下来我们动手进行CNN模型的实战训练过程。

在开始，确定模型训练基本过程

1. 准备训练数据集、测试数据集、预测数据集
2. CNN模型编码
3. 模型训练、测试
4. 模型预测、部署



**1.准备数据**

通过实现思路第1-2步，可以得到相关图片验证码字符数据，笔者这里准备训练集500多张（这里得感谢我妹子花时间帮我在标注系统上手动标注的初始数据集~~），测试集30多张，预测5张。读者在python项目拉取下来后，对应的文件夹下面已有全部数据，对应路径如下：

src_img：训练数据集

test_src_img：测试数据集

usage_src_img：预测数据集

在准备好图片验证码数据后，本次案例需要先进行字符切割预处理（其他常用验证码需要读者自己调整），对应文件image_split，以下是main方法代码

```
if __name__ == '__main__':
    split_image_dir(SRC_IMG_DIR)
    
    split_test_image()
```

执行字符切割后，对应的训练集字母分类在letter_template目录下，测试集字母分类在letter_test目录下。

数据集类：net_data.py，下面是主要代码

```
labels = []
#2-9
for i in range(8):
    labels.append(50 + i)
#A-Z    
for i in range(26):
    labels.append(65 + i)

class VerCodeDataset(Dataset):
    def __init__(self, image_dir="./letter_template/"):
        l = os.listdir(image_dir)
        self.data = []
        self.label = []
        for d in l:
            fs = os.listdir("{}{}".format(image_dir, d))
            for f in fs:
                fup = "{}{}/{}".format(image_dir, d, f)
                #图片numpy转tensor
                t = torch.from_numpy(io.imread(fup)).float() / 255
                #将二维值标准化
                norl = transforms.Normalize(t.mean(), t.std())
                self.data.append(norl(t.reshape(1, 40, 40)))
                #添加字符对应标签序号
                self.label.append(labels.index(ord(d)))
```

数据集值制作描述可参考该文章链接：[数据集制作参考文章](https://zhuanlan.zhihu.com/p/358671390)

**2.CNN模型编码**

本文验证码的识别与MNIST的识别相当类似，模型这块采用简单的前馈神经网络，它接收输入，让输入一个接着一个的通过一些层，最后给出输出。下面是minst网络结构图：

[PyTorch 神经网络 - PyTorch官方教程中文版](https://link.zhihu.com/?target=http%3A//pytorch.panchuang.net/SecondSection/neural_networks/)

![mnist](/img/in-post/post-verifycode-recognize/mnist.png)

一个典型的神经网络训练过程包括以下几点：

1.定义一个包含可训练参数的神经网络

2.迭代整个输入

3.通过神经网络处理输入

4.计算损失(loss)

5.反向传播梯度到神经网络的参数

6.更新网络的参数，典型的用一个简单的更新方法：weight = weight - learning_rate *gradient

定义神经网络（net_train.py）：

```
class Net(nn.Module):
    def __init__(self, dropout=0.1):
        super(Net, self).__init__()
        self.dropout = nn.Dropout(dropout)
       	#第一层，卷积核个数从6改成10
        self.conv1 = nn.Conv2d(1, 10, 5)
        #第二层，卷积核个数从10改成25
        self.conv2 = nn.Conv2d(10, 25, 5)
        
        #全连接层1，40*40的字符图经过2层卷积+2层池化变成7*7
        self.fc1 = nn.Linear(1 * 25 * 7 * 7, 120)
        #全连接层2
        self.fc2 = nn.Linear(120, 84)
        #最后全连接3层为输出层，本案例验证码分类一共34类，[2-9,A-Z],改为34。
        self.fc3 = nn.Linear(84, 34)

    def forward(self, x):
        # 池化出来大小直接除2
        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
        #防止过拟合
        x = self.dropout(x)
        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))
        x = self.dropout(x)
        x = x.view(-1, self.num_flat_features(x))
        #神经元relu激活函数
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

    def num_flat_features(self, x):
        size = x.size()[1:]  # all dimensions except the batch dimension
        num_features = 1
        for s in size:
            num_features *= s
        return num_features
```

下方代码中：

```
self.fc1 = nn.Linear(1 * 25 * 7 * 7, 120)
```

全连接层第一个参数的大小：

[40,40]经过[5,5]卷积核->[35,35]

[35,35]经过[2,2]池化->[18,18]

[18,18]经过[5,5]卷积核->[13,13]

[13,13]经过[2,2]池化->[7,7]

上层卷积层一共25个卷积核，因此这里的大小为``1（通道数）*25*7*7 ``= 1225，至于后面全连接的84可以随便改，和下层全连接层保持一致即可。

以上就是模型定义的代码了，读者有兴趣的也可以自行用其他模型训练

**3.模型训练、测试**

net_train.py文件提供的训练代码支持GPU训练，在没有NVDIA显卡和安装pytorch对应版本的CUDA库，默认是使用CPU训练，笔者对二种训练方式都进行了尝试，下面是训练对比情况：

```
数据量：2286张 40*40 单通道字符图片
batch_size: 50
epoch: 200

设备 		 		时间
GTX 1070TI	 	 25s
AMD R7 4750U PRO  4min
```

总结，数据量大，有条件上GTX显卡就用显卡训练，训练效率高出CPU数量级

[cuda安装文章链接](https://www.cnblogs.com/yang520ming/p/10677110.html)

这里是cuda安装注意事项：

```
1.更新nvida显卡驱动程序，然后看cuda版本
2.找pytorch对应cuda的版本安装
```

train方法代码如下：

```
def train_gpu():
    use_cuda = torch.cuda.is_available()
    if(use_cuda):
        print("use gpu cuda")
    else:
        print("use cpu")

    device = torch.device("cuda:0" if use_cuda else "cpu")
    net = Net()
    net.to(device)
	
	#随机梯度下降
    opt = optim.SGD(net.parameters(), lr=0.01)
    #迭代数据200次
    epoch = 200
    #单批次数据为50个
    batch_size = 50
    
    trainloader = data.trainloader(batch_size)
    st = datetime.datetime.now()
    loss = 0

    for e in range(epoch):
        for step, d in enumerate(trainloader):
            data_cuda =  d["data"].to(device)
            label_cuda = d["label"].to(device)
            #每次反向传播后，梯度清零
            opt.zero_grad()
            #前向传播
            out = net(data_cuda)
            #分类问题选用交叉熵损失函数
            lf = nn.CrossEntropyLoss()
            #计算损失
            loss = lf(out, label_cuda)
            #反向传播修改神经元参数
            loss.backward()
            opt.step()

			#每迭代50次或第一个批次步骤数据输出损失值
            if (e % 50 == 0 or step == 1):
                print("e : {} , step : {}, loss : {}".format(e, step, loss))

    print("loss : {}".format(loss))
    #输出训练时间
    print("cost time:",datetime.datetime.now() - st)
    #保存模型
    saveModel(net, opt)
```

描述见上面代码注释，对概念理解有问题建议可以再看下这个up主的视频，笔者觉得讲得非常不错：

[神经网络学习理解](https://space.bilibili.com/504715181?spm_id_from=333.788.b_765f7570696e666f.1)



下面给出训练、测试过程中的效果图：

GPU模型-训练集训练：

![image-20210826140758413](/img/in-post/post-verifycode-recognize/GPU模型-训练集训练.png)

**CPU模型-训练集训练**：

![image-20210826125759703](/img/in-post/post-verifycode-recognize/CPU模型-训练集训练1.png)

![image-20210826123339172](/img/in-post/post-verifycode-recognize/CPU模型-训练集训练2.png)

可以看到迭代200次，花费4分钟的训练，模型趋于拟合效果，次数越往后梯度下降越慢。其实在迭代100次之后就接近稳定来回振荡，损失值减少越慢，最后的损失值为0.0016，拟合效果还不错，如果增加训练数据量、迭代次数、优化部分字符串的切割，可以让模型效果更好，读者可自行实践。

**CPU模型-测试集测试**：

代码见net_test.py

![image-20210826125225081](/img/in-post/post-verifycode-recognize/CPU模型-测试集测试.png)

可以看到152个字符，97%的准确率，部分字符切割问题会导致准确率下降，不过问题不大，基本达到个人项目可用程度，Nice~~

**4.模型预测、部署**

经过1,2,3步循环过程后，可以用一个相对拟合稳定的模型进行预测集预测，因为过拟合的问题，可能有些模型在测试集表现较好，在测试时效果就不太好，这里需要对训练数据，模型参数进行排

**CPU模型-预测集测试**：

代码见net_usage.py

![image-20210826125926421](/img/in-post/post-verifycode-recognize/CPU模型-预测集测试.png)

上图可以看到，5张验证码的字符全部预测正确



**CPU模型-部署：**

使用python的web框架Flask API，编写图片验证码识别POST接口，传入文件路径，启动web应用，以下是通过本机文件路径识别接口代码，详细代码见net_flask.py

```
@app.route('/recognize/path', methods=['POST'])
def recognize_path():
    filePathList = request.json['filePathList']
    code = CODE_SUCCESS
    msg = MSG_SUCCESS
    data = []
    for filePath in filePathList:
        if not os.path.exists(filePath):
            # code = CODE_FAIL
            # msg = "文件不存在"
            print("文件不存在:", filePath)
            data.append("")
            continue
        else:
            labels = usage_model.usage(filePath)
            data.append(''.join(labels))
    result = {'code': code, "msg": msg, "data": data}
    return jsonify(result)
```

模型-Flask Web App启动效果：

![image-20210826141229839](/img/in-post/post-verifycode-recognize/模型Flask启动效果.png)

Postman接口测试效果：

![image-20210826141433926](/img/in-post/post-verifycode-recognize/Postman接口测试效果.png)

Web页面批量请求-预测：

![image-20210826141721678](/img/in-post/post-verifycode-recognize/Web页面批量请求-预测.png)



好的，以上就是笔者图片验证码识别案例中的卷积神经网络模型训练、测试、部署的全部内容了，总的来说，从结果看模型预测效果还是非常不错的，首先利用标注系统进行人工标注初始数据集、下载数据集，然后再进行数据集的准备，接着进行模型的编码、训练和测试，然后利用训练出来的模型进行数据预测，通过人工判断修正再把加入到训练集中，从而低时间成本、高效率增加训练数据量。

整个过程下来，读者就会熟悉到CNN神经网络在图片特征提取的魅力之处，其原理还是利用概率论、机器学习知识，在多层CNN模型下，通过多层感知机的激活函数、随机梯度下降法、损失函数、反向传播等机制进行复杂非线性模型参数的调节，使得训练处理的模型概率分布尽可能接近人脑中标注数据的概率模型。当然，读者看到这里觉得这里面还有很多疑问和问题，请不要气馁，整个机器学习、神经网络的知识体系是非常庞大的，从数学理论到计算机算法，再到工程框架，细节一步步被隐藏，请保持好奇心和思考，持续了解和学习，未来可能等知识积累到一定程度，那么很多问题就会明白和理解。说的东西有点多了，哈哈，总之还是，信息时代合理利用互联网上的资源。

接下来讲述最后一部分，就是所有项目模块的部署部分，这部分内容不会太难，如果读者不感兴趣可以跳过，可以利用笔者部署到线上的系统进行体验，服务器带宽有限，有资源的读者可以自己部署一套：

[线上效果体验地址](http://139.9.191.103:8084/)



##### 4.项目线上部署

**1.标注系统VUE前端**

可参考前端项目README-zh.md文章

```
#构建包
npm run build:prod

#上传服务器
省略

#配置nginx
upstream mark_service{
	server localhost:8088;
}

server {
	listen       8084;
	listen       [::]:8084;
	server_name  _;
	#access_log  logs/host.access.log  main;

	location / {
		root   /app/mark_data_service/webui/;
		index  index.html index.htm;
		 add_header 'Access-Control-Allow-Origin' '*';
					add_header 'Access-Control-Allow-Credentials' 'true';
					add_header 'Access-Control-Allow-Methods' 'GET';
	}

	location /api/ {
	   proxy_pass http://mark_service/;
	   proxy_set_header            Host $host;
	}

	error_page   500 502 503 504  /50x.html;
	location = /50x.html {
		root   html;
	}
}
```

前端文件服务器目录：

![image-20210826144224419](/img/in-post/post-verifycode-recognize/前端文件服务器目录.png)

**2.标注系统Java后端部署**

```
#打包
maven clean install package

#拷贝jar包到服务器
省略

#jdk/mysql/redis部署
省略

#启动项目
nohup java -jar xxx.jar &

#查看启动日志
tail -f nohup.out
```

后端文件服务器目录：

![image-20210826144651003](/img/in-post/post-verifycode-recognize/后端文件服务器目录.png)

后端启动日志：

![image-20210826144822845](/img/in-post/post-verifycode-recognize/后端启动日志.png)

**3.Python模型部署**

```
#拷贝python文件、cpu模型到服务器
省略

#python3/pipreqs导出依赖包/pip安装包
省略
注意项：服务器安装pytorch安装MemoryError问题，需要加上pip --no-cache-dir install 

#启动项目
nohup python3 net_flask.py &

#查看启动日志
tail -f nohup.out
```

Flask Web App启动日志：

![image-20210826145229373](/img/in-post/post-verifycode-recognize/Flask启动日志.png)



好的，到了这里，项目部署全部大功告成。这块内容没啥技术难度，就是安装运行环境，配置文件，最后启动项目。这些项目服务在服务器单机部署，代码暂无发现bug，部分结果截图暂未提供，读者可以自行下载代码使用IDE运行工程实践，有什么问题和想法随时可以留言或者联系小编。



#### 总结

以上就是笔者历时2-3个月从把多年前的想法实现从可行性分析，到前置知识学习，再到功能分析、设计、开发、测试和部署，基本上是独立学习并完成的，相信看到这里的读者我想都是技术很牛逼的大佬了~~。

总的来说，用到的技术层次不是特别深，主要是笔者自己利用多年企业中的项目开发经验，整合了标注前后端系统，CNN神经网络图片模型识别是现学先用的，用的模型偏简单。在笔者实现这个项目功能的过程中，深深意识到了神经网络模型特定领域的强大之处，其关联的学科知识非常多，同时也看到了自己的工科数学、算法基础较薄弱，后面会花时间去补上这些不足之处，这样才能更容易理解、把玩现有的各种算法模型。大家都知道，在现在这个时间节点，互联网行业已经进入下半场，很多功能需求不再是增删改查，而是大数据，超大规模算力场景，总之未来机器会取代人类很多方面的基础能力。XDM，还能说啥呢，做为一名向上的程序猿，从现在开始，学习（卷）起来，在人工智能时代，不要让自己的能力停留在CRUD层面。

最后，读者在下载代码使用IDE运行工程实践的过程中，有什么问题和想法随时可以留言或者联系小编。



#### 参考资料汇总 

[1.常用验证码的识别方法](https://zhuanlan.zhihu.com/p/47703273)
[2.Pytorch实现验证码识别](https://www.zhihu.com/column/c_1355984533385265153)
[3.OpenCV文章专栏](https://blog.csdn.net/yukinoai/category_9283880.html)
[4.OpenCV-Python视频](https://www.bilibili.com/video/BV1tb4y1C7j7)
[5.微积分](https://www.bilibili.com/video/BV1Eb411u7Fw)
[6.线性代数](https://www.bilibili.com/video/BV1aW411Q7x1)
[7.概率论](https://www.bilibili.com/video/BV1ot411y7mU)
[8.计算机数学基础](https://www.bilibili.com/video/BV1AB4y1K7kM)
[9.理解卷积意义](https://www.bilibili.com/video/BV1VV411478E)
[10.前馈神经网络](https://www.bilibili.com/video/BV1Tt411s7fK)
[11.神经网络学习理解](https://space.bilibili.com/504715181?spm_id_from=333.788.b_765f7570696e666f.1)
[12.Numpy中文教程](https://www.runoob.com/numpy/numpy-tutorial.html)
[13.PyTorch中文教程](https://pytorch.panchuang.net/SecondSection/neural_networks/)
[14.PyTorch视频](https://www.bilibili.com/video/BV1t64y1t7V8)

